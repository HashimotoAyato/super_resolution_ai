{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_SIZE = 128\n",
    "WINDOW_SIZE = ANSWER_SIZE / 2\n",
    "MINI_BATCH = 10\n",
    "EPOCH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 images loaded.(train:valid=20:10)\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('./dataset/images/*')\n",
    "train_files = files[0:20]\n",
    "valid_files = files[20:30]\n",
    "print('{} images loaded.(train:valid={}:{})'.format(len(files),len(train_files),len(valid_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "        self.toTensor = torchvision.transforms.ToTensor()\n",
    "        self.randomCrop = torchvision.transforms.RandomCrop(ANSWER_SIZE, padding = ANSWER_SIZE-1)\n",
    "        self.augmentation = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ColorJitter(),\n",
    "            torchvision.transforms.RandomGrayscale(p=0.1),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.RandomVerticalFlip(),\n",
    "            torchvision.transforms.RandomInvert(p=0.1)\n",
    "        ])\n",
    "        self.downsize = torchvision.transforms.Resize(int(ANSWER_SIZE/2))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read image\n",
    "        image = Image.open(self.files[idx])\n",
    "        image = self.toTensor(image)\n",
    "        # random crop\n",
    "        image = self.randomCrop(image)\n",
    "        # augmentation\n",
    "        large = self.augmentation(image)\n",
    "        # downsize\n",
    "        small = self.downsize(large)\n",
    "        return small, large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UpSampleNet, self).__init__()\n",
    "        self.input = self.output = 0\n",
    "        self.layer1 = self.layer2 = self.layer3 = self.layer4 = self.layer5 = 0\n",
    "        \n",
    "        self.step1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(32), torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(32), torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.step2 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            torch.nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(64), torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(64), torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.step3 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            torch.nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(128), torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(128), torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.deconv1 = torch.nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=2,stride=2)\n",
    "\n",
    "        self.step4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(64), torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(64), torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.deconv2 = torch.nn.ConvTranspose2d(in_channels=64,out_channels=32,kernel_size=2,stride=2)\n",
    "\n",
    "        self.step5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(32), torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(32), torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.deconv3 = torch.nn.ConvTranspose2d(in_channels=32,out_channels=16,kernel_size=2,stride=2)\n",
    "\n",
    "        self.step6 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=16,out_channels=8,kernel_size=3,padding=1),\n",
    "            torch.nn.BatchNorm2d(8), torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=8,out_channels=3,kernel_size=3,padding=1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, small):\n",
    "        self.input = small\n",
    "        # Encode\n",
    "        self.layer1 = self.step1(self.input)\n",
    "        self.layer2 = self.step2(self.layer1)\n",
    "        self.layer3 = self.step3(self.layer2)\n",
    "        # Decode\n",
    "        self.layer3 = self.deconv1(self.layer3)\n",
    "        self.layer4 = self.step4(torch.cat((self.layer3,self.layer2),dim=1))\n",
    "        self.layer4 = self.deconv2(self.layer4)\n",
    "        self.layer5 = self.step5(torch.cat((self.layer4,self.layer1),dim=1))\n",
    "        self.layer5 = self.deconv3(self.layer5)\n",
    "        self.output = self.step6(self.layer5)\n",
    "        return self.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = Dataset(train_files), Dataset(valid_files)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=MINI_BATCH,num_workers=os.cpu_count(),pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=MINI_BATCH,num_workers=os.cpu_count(),pin_memory=True)\n",
    "train_history, valid_history = {'loss':[]}, {'loss':[]}\n",
    "\n",
    "net = UpSampleNet()\n",
    "optim = torch.optim.Adam(params=net.parameters(),lr=0.0001)\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import LargeZipFile\n",
    "\n",
    "\n",
    "def train_valid(mode, model, loader, loss_function, optim, history):\n",
    "    train = True if mode == 'train' else False\n",
    "    model.train(train)\n",
    "    loss_sum = 0\n",
    "\n",
    "    for small, large in loader:\n",
    "        if train: optim.zero_grad()\n",
    "        outputs = model(small)\n",
    "        loss = loss_function(outputs, large)\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "    history['loss'].append(loss_sum / len(loader))\n",
    "    \n",
    "    log = '[Train]' if train else '[Valid]'\n",
    "    log += ' loss:' + str(history['loss'][-1])\n",
    "    print(log)\n",
    "\n",
    "def infer(model, small, padding=WINDOW_SIZE-1, stride=WINDOW_SIZE):\n",
    "    model.train(False)\n",
    "    h,w = len(small[0]), len(small[0,0])\n",
    "    small = torchvision.transforms.functional.pad(small, padding)\n",
    "    large = torch.zeros(len(small),len(small[0])*2,len(small[0,0]*2))\n",
    "\n",
    "    top = left = 0\n",
    "    while len(small[0]) - top <= WINDOW_SIZE:\n",
    "        while len(small[0,0]) - left <= WINDOW_SIZE:\n",
    "            input = torchvision.transforms.functional.crop(small,top,left,WINDOW_SIZE,WINDOW_SIZE)\n",
    "            large[:,top*2:top*2+ANSWER_SIZE,left*2:left*2+ANSWER_SIZE] = model(input)\n",
    "    \n",
    "    large = torchvision.transforms.functional.center_crop(large,[h,w])\n",
    "    return large\n",
    "\n",
    "def plot_graph(train_loss, valid_loss):\n",
    "    plt.figure()\n",
    "    plt.ioff()\n",
    "    plt.plot(range(1, len(train_loss)+1), train_loss, label = 'train')\n",
    "    plt.plot(range(1, len(valid_loss)+1), valid_loss, label = 'valid')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig('./outputs/valid/' + '{}epoch_loss.png'.format(len(train_loss)), facecolor='white')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1 Epoch ---\n",
      "[Train] loss:0.1551910862326622\n",
      "[Valid] loss:0.10784023255109787\n",
      "--- 2 Epoch ---\n",
      "[Train] loss:0.12218901515007019\n",
      "[Valid] loss:0.08526812493801117\n",
      "--- 3 Epoch ---\n",
      "[Train] loss:0.13182483986020088\n",
      "[Valid] loss:0.11819498240947723\n",
      "--- 4 Epoch ---\n",
      "[Train] loss:0.11450852826237679\n",
      "[Valid] loss:0.11753392219543457\n",
      "--- 5 Epoch ---\n",
      "[Train] loss:0.11182986199855804\n",
      "[Valid] loss:0.10486562550067902\n",
      "--- 6 Epoch ---\n",
      "[Train] loss:0.11924086138606071\n",
      "[Valid] loss:0.128995880484581\n",
      "--- 7 Epoch ---\n",
      "[Train] loss:0.12303702160716057\n",
      "[Valid] loss:0.09180113673210144\n",
      "--- 8 Epoch ---\n",
      "[Train] loss:0.11128494143486023\n",
      "[Valid] loss:0.09868933260440826\n",
      "--- 9 Epoch ---\n",
      "[Train] loss:0.0932990163564682\n",
      "[Valid] loss:0.1269991397857666\n",
      "--- 10 Epoch ---\n",
      "[Train] loss:0.11625882983207703\n",
      "[Valid] loss:0.09036464989185333\n",
      "--- 11 Epoch ---\n",
      "[Train] loss:0.10877098515629768\n",
      "[Valid] loss:0.12136247754096985\n",
      "--- 12 Epoch ---\n",
      "[Train] loss:0.09628643095493317\n",
      "[Valid] loss:0.12366890162229538\n",
      "--- 13 Epoch ---\n",
      "[Train] loss:0.09771914780139923\n",
      "[Valid] loss:0.10325299948453903\n",
      "--- 14 Epoch ---\n",
      "[Train] loss:0.09767880290746689\n",
      "[Valid] loss:0.1353616863489151\n",
      "--- 15 Epoch ---\n",
      "[Train] loss:0.11155478656291962\n",
      "[Valid] loss:0.08882082253694534\n",
      "--- 16 Epoch ---\n",
      "[Train] loss:0.10041384026408195\n",
      "[Valid] loss:0.08067131787538528\n",
      "--- 17 Epoch ---\n",
      "[Train] loss:0.0955660343170166\n",
      "[Valid] loss:0.05345924571156502\n",
      "--- 18 Epoch ---\n",
      "[Train] loss:0.09202219173312187\n",
      "[Valid] loss:0.07780251652002335\n",
      "--- 19 Epoch ---\n",
      "[Train] loss:0.10048827528953552\n",
      "[Valid] loss:0.08576095104217529\n",
      "--- 20 Epoch ---\n",
      "[Train] loss:0.09300916269421577\n",
      "[Valid] loss:0.06868068873882294\n",
      "--- 21 Epoch ---\n",
      "[Train] loss:0.08452555537223816\n",
      "[Valid] loss:0.09041396528482437\n",
      "--- 22 Epoch ---\n",
      "[Train] loss:0.08453270047903061\n",
      "[Valid] loss:0.06200294941663742\n",
      "--- 23 Epoch ---\n",
      "[Train] loss:0.0791497752070427\n",
      "[Valid] loss:0.06964755058288574\n",
      "--- 24 Epoch ---\n",
      "[Train] loss:0.10091375932097435\n",
      "[Valid] loss:0.06378722935914993\n",
      "--- 25 Epoch ---\n",
      "[Train] loss:0.10071303322911263\n",
      "[Valid] loss:0.07024452835321426\n",
      "--- 26 Epoch ---\n",
      "[Train] loss:0.08074041828513145\n",
      "[Valid] loss:0.06484239548444748\n",
      "--- 27 Epoch ---\n",
      "[Train] loss:0.0819493904709816\n",
      "[Valid] loss:0.07657928019762039\n",
      "--- 28 Epoch ---\n",
      "[Train] loss:0.09665355831384659\n",
      "[Valid] loss:0.04670869931578636\n",
      "--- 29 Epoch ---\n",
      "[Train] loss:0.08542924001812935\n",
      "[Valid] loss:0.049279093742370605\n",
      "--- 30 Epoch ---\n",
      "[Train] loss:0.08087844029068947\n",
      "[Valid] loss:0.06265535950660706\n",
      "--- 31 Epoch ---\n",
      "[Train] loss:0.08050082251429558\n",
      "[Valid] loss:0.05799560621380806\n",
      "--- 32 Epoch ---\n",
      "[Train] loss:0.07561255991458893\n",
      "[Valid] loss:0.07015375792980194\n",
      "--- 33 Epoch ---\n",
      "[Train] loss:0.08175468072295189\n",
      "[Valid] loss:0.07197467237710953\n",
      "--- 34 Epoch ---\n",
      "[Train] loss:0.07387749664485455\n",
      "[Valid] loss:0.06004795804619789\n",
      "--- 35 Epoch ---\n",
      "[Train] loss:0.0786856971681118\n",
      "[Valid] loss:0.04973336681723595\n",
      "--- 36 Epoch ---\n",
      "[Train] loss:0.08235761895775795\n",
      "[Valid] loss:0.05223578214645386\n",
      "--- 37 Epoch ---\n",
      "[Train] loss:0.06164463795721531\n",
      "[Valid] loss:0.04903620108962059\n",
      "--- 38 Epoch ---\n",
      "[Train] loss:0.058757612481713295\n",
      "[Valid] loss:0.05042918026447296\n",
      "--- 39 Epoch ---\n",
      "[Train] loss:0.07475319132208824\n",
      "[Valid] loss:0.034079160541296005\n",
      "--- 40 Epoch ---\n",
      "[Train] loss:0.06229112483561039\n",
      "[Valid] loss:0.04489646852016449\n",
      "--- 41 Epoch ---\n",
      "[Train] loss:0.0666347611695528\n",
      "[Valid] loss:0.06403466314077377\n",
      "--- 42 Epoch ---\n",
      "[Train] loss:0.0669412799179554\n",
      "[Valid] loss:0.05007157847285271\n",
      "--- 43 Epoch ---\n",
      "[Train] loss:0.08055447787046432\n",
      "[Valid] loss:0.03808047994971275\n",
      "--- 44 Epoch ---\n",
      "[Train] loss:0.07929195091128349\n",
      "[Valid] loss:0.0550660602748394\n",
      "--- 45 Epoch ---\n",
      "[Train] loss:0.06755998358130455\n",
      "[Valid] loss:0.03286982700228691\n",
      "--- 46 Epoch ---\n",
      "[Train] loss:0.050802960991859436\n",
      "[Valid] loss:0.04649040848016739\n",
      "--- 47 Epoch ---\n",
      "[Train] loss:0.0695048738270998\n",
      "[Valid] loss:0.041124336421489716\n",
      "--- 48 Epoch ---\n",
      "[Train] loss:0.04778794106096029\n",
      "[Valid] loss:0.04718173295259476\n",
      "--- 49 Epoch ---\n",
      "[Train] loss:0.05303221195936203\n",
      "[Valid] loss:0.03915250301361084\n",
      "--- 50 Epoch ---\n",
      "[Train] loss:0.0638667643070221\n",
      "[Valid] loss:0.04307393729686737\n",
      "--- 51 Epoch ---\n",
      "[Train] loss:0.04675137996673584\n",
      "[Valid] loss:0.04204617068171501\n",
      "--- 52 Epoch ---\n",
      "[Train] loss:0.06092587672173977\n",
      "[Valid] loss:0.033605922013521194\n",
      "--- 53 Epoch ---\n",
      "[Train] loss:0.057230664417147636\n",
      "[Valid] loss:0.030407479032874107\n",
      "--- 54 Epoch ---\n",
      "[Train] loss:0.0629781149327755\n",
      "[Valid] loss:0.028777727857232094\n",
      "--- 55 Epoch ---\n",
      "[Train] loss:0.05523306876420975\n",
      "[Valid] loss:0.03482317551970482\n",
      "--- 56 Epoch ---\n",
      "[Train] loss:0.08064605668187141\n",
      "[Valid] loss:0.029932187870144844\n",
      "--- 57 Epoch ---\n",
      "[Train] loss:0.052252065390348434\n",
      "[Valid] loss:0.03467477113008499\n",
      "--- 58 Epoch ---\n",
      "[Train] loss:0.04914859123528004\n",
      "[Valid] loss:0.03977062553167343\n",
      "--- 59 Epoch ---\n",
      "[Train] loss:0.058238985016942024\n",
      "[Valid] loss:0.03536929935216904\n",
      "--- 60 Epoch ---\n",
      "[Train] loss:0.05895278602838516\n",
      "[Valid] loss:0.03821839764714241\n",
      "--- 61 Epoch ---\n",
      "[Train] loss:0.05199211463332176\n",
      "[Valid] loss:0.03740914165973663\n",
      "--- 62 Epoch ---\n",
      "[Train] loss:0.05794372782111168\n",
      "[Valid] loss:0.02503683976829052\n",
      "--- 63 Epoch ---\n",
      "[Train] loss:0.06381976045668125\n",
      "[Valid] loss:0.03451890870928764\n",
      "--- 64 Epoch ---\n",
      "[Train] loss:0.04064437374472618\n",
      "[Valid] loss:0.026430834084749222\n",
      "--- 65 Epoch ---\n",
      "[Train] loss:0.05597242712974548\n",
      "[Valid] loss:0.03318833187222481\n",
      "--- 66 Epoch ---\n",
      "[Train] loss:0.05613406002521515\n",
      "[Valid] loss:0.023762384429574013\n",
      "--- 67 Epoch ---\n",
      "[Train] loss:0.04697132483124733\n",
      "[Valid] loss:0.029627805575728416\n",
      "--- 68 Epoch ---\n",
      "[Train] loss:0.041137379594147205\n",
      "[Valid] loss:0.0360042080283165\n",
      "--- 69 Epoch ---\n",
      "[Train] loss:0.04676070995628834\n",
      "[Valid] loss:0.0280069038271904\n",
      "--- 70 Epoch ---\n",
      "[Train] loss:0.04877630993723869\n",
      "[Valid] loss:0.0390448234975338\n",
      "--- 71 Epoch ---\n",
      "[Train] loss:0.04847295768558979\n",
      "[Valid] loss:0.030667215585708618\n",
      "--- 72 Epoch ---\n",
      "[Train] loss:0.04762713611125946\n",
      "[Valid] loss:0.03741231933236122\n",
      "--- 73 Epoch ---\n",
      "[Train] loss:0.043720551766455173\n",
      "[Valid] loss:0.0252530500292778\n",
      "--- 74 Epoch ---\n",
      "[Train] loss:0.04596147686243057\n",
      "[Valid] loss:0.030118560418486595\n",
      "--- 75 Epoch ---\n",
      "[Train] loss:0.049372898414731026\n",
      "[Valid] loss:0.03128919377923012\n",
      "--- 76 Epoch ---\n",
      "[Train] loss:0.05333570949733257\n",
      "[Valid] loss:0.019203033298254013\n",
      "--- 77 Epoch ---\n",
      "[Train] loss:0.043297041207551956\n",
      "[Valid] loss:0.029984746128320694\n",
      "--- 78 Epoch ---\n",
      "[Train] loss:0.04523248411715031\n",
      "[Valid] loss:0.031064098700881004\n",
      "--- 79 Epoch ---\n",
      "[Train] loss:0.04327072761952877\n",
      "[Valid] loss:0.024310268461704254\n",
      "--- 80 Epoch ---\n",
      "[Train] loss:0.03812303766608238\n",
      "[Valid] loss:0.020090345293283463\n",
      "--- 81 Epoch ---\n",
      "[Train] loss:0.047096166759729385\n",
      "[Valid] loss:0.028163159266114235\n",
      "--- 82 Epoch ---\n",
      "[Train] loss:0.05005992017686367\n",
      "[Valid] loss:0.020600609481334686\n",
      "--- 83 Epoch ---\n",
      "[Train] loss:0.04789448343217373\n",
      "[Valid] loss:0.0297081358730793\n",
      "--- 84 Epoch ---\n",
      "[Train] loss:0.043015219271183014\n",
      "[Valid] loss:0.017754744738340378\n",
      "--- 85 Epoch ---\n",
      "[Train] loss:0.038197385147213936\n",
      "[Valid] loss:0.025516239926218987\n",
      "--- 86 Epoch ---\n",
      "[Train] loss:0.04035601671785116\n",
      "[Valid] loss:0.027727702632546425\n",
      "--- 87 Epoch ---\n",
      "[Train] loss:0.04263404756784439\n",
      "[Valid] loss:0.025952188298106194\n",
      "--- 88 Epoch ---\n",
      "[Train] loss:0.0429789163172245\n",
      "[Valid] loss:0.02483898028731346\n",
      "--- 89 Epoch ---\n",
      "[Train] loss:0.04044543206691742\n",
      "[Valid] loss:0.019304268062114716\n",
      "--- 90 Epoch ---\n",
      "[Train] loss:0.030910867266356945\n",
      "[Valid] loss:0.02173616923391819\n",
      "--- 91 Epoch ---\n",
      "[Train] loss:0.046777576208114624\n",
      "[Valid] loss:0.016699591651558876\n",
      "--- 92 Epoch ---\n",
      "[Train] loss:0.040807269513607025\n",
      "[Valid] loss:0.025577766820788383\n",
      "--- 93 Epoch ---\n",
      "[Train] loss:0.040413374081254005\n",
      "[Valid] loss:0.030144330114126205\n",
      "--- 94 Epoch ---\n",
      "[Train] loss:0.05841602012515068\n",
      "[Valid] loss:0.019007859751582146\n",
      "--- 95 Epoch ---\n",
      "[Train] loss:0.048529740422964096\n",
      "[Valid] loss:0.02384045720100403\n",
      "--- 96 Epoch ---\n",
      "[Train] loss:0.04984322004020214\n",
      "[Valid] loss:0.018741365522146225\n",
      "--- 97 Epoch ---\n",
      "[Train] loss:0.03764980472624302\n",
      "[Valid] loss:0.018214387819170952\n",
      "--- 98 Epoch ---\n",
      "[Train] loss:0.03374609537422657\n",
      "[Valid] loss:0.01477001328021288\n",
      "--- 99 Epoch ---\n",
      "[Train] loss:0.04247697349637747\n",
      "[Valid] loss:0.022128192707896233\n",
      "--- 100 Epoch ---\n",
      "[Train] loss:0.044463285245001316\n",
      "[Valid] loss:0.022296754643321037\n",
      "--- 101 Epoch ---\n",
      "[Train] loss:0.03364393301308155\n",
      "[Valid] loss:0.024076348170638084\n",
      "--- 102 Epoch ---\n",
      "[Train] loss:0.04633476957678795\n",
      "[Valid] loss:0.02321426384150982\n",
      "--- 103 Epoch ---\n",
      "[Train] loss:0.03791912831366062\n",
      "[Valid] loss:0.02535090781748295\n",
      "--- 104 Epoch ---\n",
      "[Train] loss:0.0349236223846674\n",
      "[Valid] loss:0.020045693963766098\n",
      "--- 105 Epoch ---\n",
      "[Train] loss:0.03859379328787327\n",
      "[Valid] loss:0.021598907187581062\n",
      "--- 106 Epoch ---\n",
      "[Train] loss:0.049310095608234406\n",
      "[Valid] loss:0.028551705181598663\n",
      "--- 107 Epoch ---\n",
      "[Train] loss:0.03626521863043308\n",
      "[Valid] loss:0.02563592605292797\n",
      "--- 108 Epoch ---\n",
      "[Train] loss:0.03795390762388706\n",
      "[Valid] loss:0.018472719937562943\n",
      "--- 109 Epoch ---\n",
      "[Train] loss:0.026366010308265686\n",
      "[Valid] loss:0.021069033071398735\n",
      "--- 110 Epoch ---\n",
      "[Train] loss:0.030952139757573605\n",
      "[Valid] loss:0.018528170883655548\n",
      "--- 111 Epoch ---\n",
      "[Train] loss:0.03864484652876854\n",
      "[Valid] loss:0.020363787189126015\n",
      "--- 112 Epoch ---\n",
      "[Train] loss:0.0365587817505002\n",
      "[Valid] loss:0.018681105226278305\n",
      "--- 113 Epoch ---\n",
      "[Train] loss:0.0313021270558238\n",
      "[Valid] loss:0.017955319955945015\n",
      "--- 114 Epoch ---\n",
      "[Train] loss:0.030463838949799538\n",
      "[Valid] loss:0.016422513872385025\n",
      "--- 115 Epoch ---\n",
      "[Train] loss:0.03368173539638519\n",
      "[Valid] loss:0.013916590251028538\n",
      "--- 116 Epoch ---\n",
      "[Train] loss:0.03741730283945799\n",
      "[Valid] loss:0.014240729622542858\n",
      "--- 117 Epoch ---\n",
      "[Train] loss:0.03466385509818792\n",
      "[Valid] loss:0.01664682850241661\n",
      "--- 118 Epoch ---\n",
      "[Train] loss:0.03406124375760555\n",
      "[Valid] loss:0.01396038569509983\n",
      "--- 119 Epoch ---\n",
      "[Train] loss:0.034450589679181576\n",
      "[Valid] loss:0.017543314024806023\n",
      "--- 120 Epoch ---\n",
      "[Train] loss:0.04305124841630459\n",
      "[Valid] loss:0.021343611180782318\n",
      "--- 121 Epoch ---\n",
      "[Train] loss:0.030566135421395302\n",
      "[Valid] loss:0.018414078280329704\n",
      "--- 122 Epoch ---\n",
      "[Train] loss:0.03365294076502323\n",
      "[Valid] loss:0.015394490212202072\n",
      "--- 123 Epoch ---\n",
      "[Train] loss:0.024149788543581963\n",
      "[Valid] loss:0.017671072855591774\n",
      "--- 124 Epoch ---\n",
      "[Train] loss:0.022329386323690414\n",
      "[Valid] loss:0.01578165777027607\n",
      "--- 125 Epoch ---\n",
      "[Train] loss:0.02010783925652504\n",
      "[Valid] loss:0.014461531303822994\n",
      "--- 126 Epoch ---\n",
      "[Train] loss:0.03146376181393862\n",
      "[Valid] loss:0.01620899699628353\n",
      "--- 127 Epoch ---\n",
      "[Train] loss:0.027510923333466053\n",
      "[Valid] loss:0.014525145292282104\n",
      "--- 128 Epoch ---\n",
      "[Train] loss:0.022860269993543625\n",
      "[Valid] loss:0.01688327081501484\n",
      "--- 129 Epoch ---\n",
      "[Train] loss:0.03425796888768673\n",
      "[Valid] loss:0.013002580963075161\n",
      "--- 130 Epoch ---\n",
      "[Train] loss:0.03826698940247297\n",
      "[Valid] loss:0.014985058456659317\n",
      "--- 131 Epoch ---\n",
      "[Train] loss:0.030027552507817745\n",
      "[Valid] loss:0.010680878534913063\n",
      "--- 132 Epoch ---\n",
      "[Train] loss:0.02947312965989113\n",
      "[Valid] loss:0.012723913416266441\n",
      "--- 133 Epoch ---\n",
      "[Train] loss:0.03877950552850962\n",
      "[Valid] loss:0.015799403190612793\n",
      "--- 134 Epoch ---\n",
      "[Train] loss:0.028314736671745777\n",
      "[Valid] loss:0.014261401258409023\n",
      "--- 135 Epoch ---\n",
      "[Train] loss:0.024573427625000477\n",
      "[Valid] loss:0.011919017881155014\n",
      "--- 136 Epoch ---\n",
      "[Train] loss:0.024115593172609806\n",
      "[Valid] loss:0.01582472212612629\n",
      "--- 137 Epoch ---\n",
      "[Train] loss:0.02911754511296749\n",
      "[Valid] loss:0.01374146994203329\n",
      "--- 138 Epoch ---\n",
      "[Train] loss:0.041547149419784546\n",
      "[Valid] loss:0.01537866797298193\n",
      "--- 139 Epoch ---\n",
      "[Train] loss:0.029115171171724796\n",
      "[Valid] loss:0.018858250230550766\n",
      "--- 140 Epoch ---\n",
      "[Train] loss:0.033590770326554775\n",
      "[Valid] loss:0.01594417542219162\n",
      "--- 141 Epoch ---\n",
      "[Train] loss:0.04805223550647497\n",
      "[Valid] loss:0.013423015363514423\n",
      "--- 142 Epoch ---\n",
      "[Train] loss:0.028319730423390865\n",
      "[Valid] loss:0.015581321902573109\n",
      "--- 143 Epoch ---\n",
      "[Train] loss:0.037341914139688015\n",
      "[Valid] loss:0.009980721399188042\n",
      "--- 144 Epoch ---\n",
      "[Train] loss:0.02890375629067421\n",
      "[Valid] loss:0.00937256682664156\n",
      "--- 145 Epoch ---\n",
      "[Train] loss:0.036031211726367474\n",
      "[Valid] loss:0.015586825087666512\n",
      "--- 146 Epoch ---\n",
      "[Train] loss:0.024355323053896427\n",
      "[Valid] loss:0.011050891131162643\n",
      "--- 147 Epoch ---\n",
      "[Train] loss:0.02839677408337593\n",
      "[Valid] loss:0.01326735969632864\n",
      "--- 148 Epoch ---\n",
      "[Train] loss:0.024369998835027218\n",
      "[Valid] loss:0.014494523406028748\n",
      "--- 149 Epoch ---\n",
      "[Train] loss:0.03495670389384031\n",
      "[Valid] loss:0.01394614391028881\n",
      "--- 150 Epoch ---\n",
      "[Train] loss:0.026464433409273624\n",
      "[Valid] loss:0.014613878913223743\n",
      "--- 151 Epoch ---\n",
      "[Train] loss:0.02614584192633629\n",
      "[Valid] loss:0.013046643696725368\n",
      "--- 152 Epoch ---\n",
      "[Train] loss:0.026869837194681168\n",
      "[Valid] loss:0.01561700738966465\n",
      "--- 153 Epoch ---\n",
      "[Train] loss:0.027518846094608307\n",
      "[Valid] loss:0.010056530125439167\n",
      "--- 154 Epoch ---\n",
      "[Train] loss:0.027823297306895256\n",
      "[Valid] loss:0.014290759339928627\n",
      "--- 155 Epoch ---\n",
      "[Train] loss:0.02192643191665411\n",
      "[Valid] loss:0.015091068111360073\n",
      "--- 156 Epoch ---\n",
      "[Train] loss:0.02192189358174801\n",
      "[Valid] loss:0.013428869657218456\n",
      "--- 157 Epoch ---\n",
      "[Train] loss:0.022126820869743824\n",
      "[Valid] loss:0.015887020155787468\n",
      "--- 158 Epoch ---\n",
      "[Train] loss:0.024806666187942028\n",
      "[Valid] loss:0.014323375187814236\n",
      "--- 159 Epoch ---\n",
      "[Train] loss:0.019498798064887524\n",
      "[Valid] loss:0.011325477622449398\n",
      "--- 160 Epoch ---\n",
      "[Train] loss:0.03199111204594374\n",
      "[Valid] loss:0.015325094573199749\n",
      "--- 161 Epoch ---\n",
      "[Train] loss:0.02763284184038639\n",
      "[Valid] loss:0.012466750107705593\n",
      "--- 162 Epoch ---\n",
      "[Train] loss:0.02576620876789093\n",
      "[Valid] loss:0.01220435369759798\n",
      "--- 163 Epoch ---\n",
      "[Train] loss:0.03726603928953409\n",
      "[Valid] loss:0.013679532334208488\n",
      "--- 164 Epoch ---\n",
      "[Train] loss:0.025694284588098526\n",
      "[Valid] loss:0.013458563014864922\n",
      "--- 165 Epoch ---\n",
      "[Train] loss:0.025240407325327396\n",
      "[Valid] loss:0.010952339507639408\n",
      "--- 166 Epoch ---\n",
      "[Train] loss:0.025088943541049957\n",
      "[Valid] loss:0.01013683807104826\n",
      "--- 167 Epoch ---\n",
      "[Train] loss:0.022110161371529102\n",
      "[Valid] loss:0.012472136877477169\n",
      "--- 168 Epoch ---\n",
      "[Train] loss:0.02789074368774891\n",
      "[Valid] loss:0.009824332781136036\n",
      "--- 169 Epoch ---\n",
      "[Train] loss:0.024854744784533978\n",
      "[Valid] loss:0.010083575733006\n",
      "--- 170 Epoch ---\n",
      "[Train] loss:0.03749771602451801\n",
      "[Valid] loss:0.013767204247415066\n",
      "--- 171 Epoch ---\n",
      "[Train] loss:0.017155585810542107\n",
      "[Valid] loss:0.011494112201035023\n",
      "--- 172 Epoch ---\n",
      "[Train] loss:0.028883952647447586\n",
      "[Valid] loss:0.014051729813218117\n",
      "--- 173 Epoch ---\n",
      "[Train] loss:0.043787192553281784\n",
      "[Valid] loss:0.012230954132974148\n",
      "--- 174 Epoch ---\n",
      "[Train] loss:0.01378767192363739\n",
      "[Valid] loss:0.009646556340157986\n",
      "--- 175 Epoch ---\n",
      "[Train] loss:0.030944674275815487\n",
      "[Valid] loss:0.009410248138010502\n",
      "--- 176 Epoch ---\n",
      "[Train] loss:0.020886151120066643\n",
      "[Valid] loss:0.012428711168467999\n",
      "--- 177 Epoch ---\n",
      "[Train] loss:0.025608993135392666\n",
      "[Valid] loss:0.012727569788694382\n",
      "--- 178 Epoch ---\n",
      "[Train] loss:0.035289675928652287\n",
      "[Valid] loss:0.011154739186167717\n",
      "--- 179 Epoch ---\n",
      "[Train] loss:0.02373872697353363\n",
      "[Valid] loss:0.010080193169414997\n",
      "--- 180 Epoch ---\n",
      "[Train] loss:0.02347944024950266\n",
      "[Valid] loss:0.008477929048240185\n",
      "--- 181 Epoch ---\n",
      "[Train] loss:0.023367654532194138\n",
      "[Valid] loss:0.013798552565276623\n",
      "--- 182 Epoch ---\n",
      "[Train] loss:0.028395455330610275\n",
      "[Valid] loss:0.010976294986903667\n",
      "--- 183 Epoch ---\n",
      "[Train] loss:0.022837955970317125\n",
      "[Valid] loss:0.013283691368997097\n",
      "--- 184 Epoch ---\n",
      "[Train] loss:0.01876125857234001\n",
      "[Valid] loss:0.011019870638847351\n",
      "--- 185 Epoch ---\n",
      "[Train] loss:0.025628277100622654\n",
      "[Valid] loss:0.009779197163879871\n",
      "--- 186 Epoch ---\n",
      "[Train] loss:0.016267175320535898\n",
      "[Valid] loss:0.010361706838011742\n",
      "--- 187 Epoch ---\n",
      "[Train] loss:0.0244308328256011\n",
      "[Valid] loss:0.010582204908132553\n",
      "--- 188 Epoch ---\n",
      "[Train] loss:0.02115323720499873\n",
      "[Valid] loss:0.012675094418227673\n",
      "--- 189 Epoch ---\n",
      "[Train] loss:0.022722378373146057\n",
      "[Valid] loss:0.008458836935460567\n",
      "--- 190 Epoch ---\n",
      "[Train] loss:0.021222051233053207\n",
      "[Valid] loss:0.009302925318479538\n",
      "--- 191 Epoch ---\n",
      "[Train] loss:0.021721087396144867\n",
      "[Valid] loss:0.008495316840708256\n",
      "--- 192 Epoch ---\n",
      "[Train] loss:0.01912300754338503\n",
      "[Valid] loss:0.009472320787608624\n",
      "--- 193 Epoch ---\n",
      "[Train] loss:0.021897196769714355\n",
      "[Valid] loss:0.010032860562205315\n",
      "--- 194 Epoch ---\n",
      "[Train] loss:0.024314512498676777\n",
      "[Valid] loss:0.012056986801326275\n",
      "--- 195 Epoch ---\n",
      "[Train] loss:0.023102272767573595\n",
      "[Valid] loss:0.010335366241633892\n",
      "--- 196 Epoch ---\n",
      "[Train] loss:0.01885597687214613\n",
      "[Valid] loss:0.00889792013913393\n",
      "--- 197 Epoch ---\n",
      "[Train] loss:0.01687359344214201\n",
      "[Valid] loss:0.010141449980437756\n",
      "--- 198 Epoch ---\n",
      "[Train] loss:0.016571046318858862\n",
      "[Valid] loss:0.0080416863784194\n",
      "--- 199 Epoch ---\n",
      "[Train] loss:0.020589138381183147\n",
      "[Valid] loss:0.009563281200826168\n",
      "--- 200 Epoch ---\n",
      "[Train] loss:0.026546993758529425\n",
      "[Valid] loss:0.011908045038580894\n",
      "--- 201 Epoch ---\n",
      "[Train] loss:0.019770161248743534\n",
      "[Valid] loss:0.01114786695688963\n",
      "--- 202 Epoch ---\n",
      "[Train] loss:0.020883467514067888\n",
      "[Valid] loss:0.011350957676768303\n",
      "--- 203 Epoch ---\n",
      "[Train] loss:0.02388827968388796\n",
      "[Valid] loss:0.012592588551342487\n",
      "--- 204 Epoch ---\n",
      "[Train] loss:0.02250533364713192\n",
      "[Valid] loss:0.007885069586336613\n",
      "--- 205 Epoch ---\n",
      "[Train] loss:0.02136817667633295\n",
      "[Valid] loss:0.011544124223291874\n",
      "--- 206 Epoch ---\n",
      "[Train] loss:0.019669125322252512\n",
      "[Valid] loss:0.008614565245807171\n",
      "--- 207 Epoch ---\n",
      "[Train] loss:0.02365764696151018\n",
      "[Valid] loss:0.008458157069981098\n",
      "--- 208 Epoch ---\n",
      "[Train] loss:0.018618743866682053\n",
      "[Valid] loss:0.011384163051843643\n",
      "--- 209 Epoch ---\n",
      "[Train] loss:0.01626086700707674\n",
      "[Valid] loss:0.009074446745216846\n",
      "--- 210 Epoch ---\n",
      "[Train] loss:0.02367470506578684\n",
      "[Valid] loss:0.012152052484452724\n",
      "--- 211 Epoch ---\n",
      "[Train] loss:0.018760467879474163\n",
      "[Valid] loss:0.009006726555526257\n",
      "--- 212 Epoch ---\n",
      "[Train] loss:0.014236405957490206\n",
      "[Valid] loss:0.011716905981302261\n",
      "--- 213 Epoch ---\n",
      "[Train] loss:0.023400649428367615\n",
      "[Valid] loss:0.010135622695088387\n",
      "--- 214 Epoch ---\n",
      "[Train] loss:0.018862904515117407\n",
      "[Valid] loss:0.01313078124076128\n",
      "--- 215 Epoch ---\n",
      "[Train] loss:0.014477916993200779\n",
      "[Valid] loss:0.009927411563694477\n",
      "--- 216 Epoch ---\n",
      "[Train] loss:0.014436486642807722\n",
      "[Valid] loss:0.00996517576277256\n",
      "--- 217 Epoch ---\n",
      "[Train] loss:0.0212314547970891\n",
      "[Valid] loss:0.007977969013154507\n",
      "--- 218 Epoch ---\n",
      "[Train] loss:0.018061033450067043\n",
      "[Valid] loss:0.0071908957324922085\n",
      "--- 219 Epoch ---\n",
      "[Train] loss:0.022330544888973236\n",
      "[Valid] loss:0.010545779950916767\n",
      "--- 220 Epoch ---\n",
      "[Train] loss:0.016509443055838346\n",
      "[Valid] loss:0.008932694792747498\n",
      "--- 221 Epoch ---\n",
      "[Train] loss:0.03213139809668064\n",
      "[Valid] loss:0.009261081926524639\n",
      "--- 222 Epoch ---\n",
      "[Train] loss:0.02487448137253523\n",
      "[Valid] loss:0.009359996765851974\n",
      "--- 223 Epoch ---\n",
      "[Train] loss:0.02281126845628023\n",
      "[Valid] loss:0.009081925265491009\n",
      "--- 224 Epoch ---\n",
      "[Train] loss:0.019953410606831312\n",
      "[Valid] loss:0.008984444662928581\n",
      "--- 225 Epoch ---\n",
      "[Train] loss:0.02836665976792574\n",
      "[Valid] loss:0.008296793326735497\n",
      "--- 226 Epoch ---\n",
      "[Train] loss:0.01782713457942009\n",
      "[Valid] loss:0.008861785754561424\n",
      "--- 227 Epoch ---\n",
      "[Train] loss:0.018857326358556747\n",
      "[Valid] loss:0.006513697095215321\n",
      "--- 228 Epoch ---\n",
      "[Train] loss:0.023485390469431877\n",
      "[Valid] loss:0.008347057737410069\n",
      "--- 229 Epoch ---\n",
      "[Train] loss:0.022503442130982876\n",
      "[Valid] loss:0.008694935590028763\n",
      "--- 230 Epoch ---\n",
      "[Train] loss:0.015600773505866528\n",
      "[Valid] loss:0.01046641543507576\n",
      "--- 231 Epoch ---\n",
      "[Train] loss:0.017917446792125702\n",
      "[Valid] loss:0.009653524495661259\n",
      "--- 232 Epoch ---\n",
      "[Train] loss:0.02143231313675642\n",
      "[Valid] loss:0.0073987338691949844\n",
      "--- 233 Epoch ---\n",
      "[Train] loss:0.021505406126379967\n",
      "[Valid] loss:0.007969354279339314\n",
      "--- 234 Epoch ---\n",
      "[Train] loss:0.014056738000363111\n",
      "[Valid] loss:0.009044152684509754\n",
      "--- 235 Epoch ---\n",
      "[Train] loss:0.016361757181584835\n",
      "[Valid] loss:0.009316937066614628\n",
      "--- 236 Epoch ---\n",
      "[Train] loss:0.012620308436453342\n",
      "[Valid] loss:0.006006165407598019\n",
      "--- 237 Epoch ---\n",
      "[Train] loss:0.017724232282489538\n",
      "[Valid] loss:0.008393790572881699\n",
      "--- 238 Epoch ---\n",
      "[Train] loss:0.01586104929447174\n",
      "[Valid] loss:0.005944840144366026\n",
      "--- 239 Epoch ---\n",
      "[Train] loss:0.014417008496820927\n",
      "[Valid] loss:0.005816509481519461\n",
      "--- 240 Epoch ---\n",
      "[Train] loss:0.017392312176525593\n",
      "[Valid] loss:0.009836421348154545\n",
      "--- 241 Epoch ---\n",
      "[Train] loss:0.025007321499288082\n",
      "[Valid] loss:0.010743824765086174\n",
      "--- 242 Epoch ---\n",
      "[Train] loss:0.0159841300919652\n",
      "[Valid] loss:0.009707449935376644\n",
      "--- 243 Epoch ---\n",
      "[Train] loss:0.01534402184188366\n",
      "[Valid] loss:0.006378598511219025\n",
      "--- 244 Epoch ---\n",
      "[Train] loss:0.013980279210954905\n",
      "[Valid] loss:0.007630699314177036\n",
      "--- 245 Epoch ---\n",
      "[Train] loss:0.017102784011512995\n",
      "[Valid] loss:0.007071347441524267\n",
      "--- 246 Epoch ---\n",
      "[Train] loss:0.021430502645671368\n",
      "[Valid] loss:0.008831235580146313\n",
      "--- 247 Epoch ---\n",
      "[Train] loss:0.020709936041384935\n",
      "[Valid] loss:0.008852910250425339\n",
      "--- 248 Epoch ---\n",
      "[Train] loss:0.022828777320683002\n",
      "[Valid] loss:0.008544565178453922\n",
      "--- 249 Epoch ---\n",
      "[Train] loss:0.017182428389787674\n",
      "[Valid] loss:0.0077809798531234264\n",
      "--- 250 Epoch ---\n",
      "[Train] loss:0.014825324527919292\n",
      "[Valid] loss:0.0081622414290905\n",
      "--- 251 Epoch ---\n",
      "[Train] loss:0.016304560005664825\n",
      "[Valid] loss:0.007802469655871391\n",
      "--- 252 Epoch ---\n",
      "[Train] loss:0.013611024711281061\n",
      "[Valid] loss:0.00803168024867773\n",
      "--- 253 Epoch ---\n",
      "[Train] loss:0.016005622688680887\n",
      "[Valid] loss:0.00833955779671669\n",
      "--- 254 Epoch ---\n",
      "[Train] loss:0.018655091989785433\n",
      "[Valid] loss:0.007810686714947224\n",
      "--- 255 Epoch ---\n",
      "[Train] loss:0.01819686498492956\n",
      "[Valid] loss:0.010273857973515987\n",
      "--- 256 Epoch ---\n",
      "[Train] loss:0.0130201387219131\n",
      "[Valid] loss:0.006403125822544098\n",
      "--- 257 Epoch ---\n",
      "[Train] loss:0.014766643289476633\n",
      "[Valid] loss:0.006004243157804012\n",
      "--- 258 Epoch ---\n",
      "[Train] loss:0.012286109384149313\n",
      "[Valid] loss:0.006743504200130701\n",
      "--- 259 Epoch ---\n",
      "[Train] loss:0.015452782157808542\n",
      "[Valid] loss:0.007545375265181065\n",
      "--- 260 Epoch ---\n",
      "[Train] loss:0.016102598514407873\n",
      "[Valid] loss:0.007025336846709251\n",
      "--- 261 Epoch ---\n",
      "[Train] loss:0.011434561107307673\n",
      "[Valid] loss:0.006683093961328268\n",
      "--- 262 Epoch ---\n",
      "[Train] loss:0.01297405268996954\n",
      "[Valid] loss:0.006941741798073053\n",
      "--- 263 Epoch ---\n",
      "[Train] loss:0.014585661701858044\n",
      "[Valid] loss:0.00820012018084526\n",
      "--- 264 Epoch ---\n",
      "[Train] loss:0.013110485393553972\n",
      "[Valid] loss:0.006323651410639286\n",
      "--- 265 Epoch ---\n",
      "[Train] loss:0.008203763980418444\n",
      "[Valid] loss:0.005619338247925043\n",
      "--- 266 Epoch ---\n",
      "[Train] loss:0.02043649833649397\n",
      "[Valid] loss:0.006188029423356056\n",
      "--- 267 Epoch ---\n",
      "[Train] loss:0.01811153069138527\n",
      "[Valid] loss:0.006956970784813166\n",
      "--- 268 Epoch ---\n",
      "[Train] loss:0.01280595175921917\n",
      "[Valid] loss:0.00495652062818408\n",
      "--- 269 Epoch ---\n",
      "[Train] loss:0.012656386941671371\n",
      "[Valid] loss:0.005727460607886314\n",
      "--- 270 Epoch ---\n",
      "[Train] loss:0.01627589063718915\n",
      "[Valid] loss:0.006715668831020594\n",
      "--- 271 Epoch ---\n",
      "[Train] loss:0.018849465996026993\n",
      "[Valid] loss:0.006232791114598513\n",
      "--- 272 Epoch ---\n",
      "[Train] loss:0.01730937883257866\n",
      "[Valid] loss:0.006916546728461981\n",
      "--- 273 Epoch ---\n",
      "[Train] loss:0.015076795592904091\n",
      "[Valid] loss:0.005812590476125479\n",
      "--- 274 Epoch ---\n",
      "[Train] loss:0.020284394966438413\n",
      "[Valid] loss:0.005289795808494091\n",
      "--- 275 Epoch ---\n",
      "[Train] loss:0.00952823250554502\n",
      "[Valid] loss:0.008615589700639248\n",
      "--- 276 Epoch ---\n",
      "[Train] loss:0.01974732894450426\n",
      "[Valid] loss:0.004718001466244459\n",
      "--- 277 Epoch ---\n",
      "[Train] loss:0.01210087863728404\n",
      "[Valid] loss:0.007685000076889992\n",
      "--- 278 Epoch ---\n",
      "[Train] loss:0.01239749789237976\n",
      "[Valid] loss:0.007529350463300943\n",
      "--- 279 Epoch ---\n",
      "[Train] loss:0.010547672864049673\n",
      "[Valid] loss:0.006466698832809925\n",
      "--- 280 Epoch ---\n",
      "[Train] loss:0.0154154053889215\n",
      "[Valid] loss:0.009367996826767921\n",
      "--- 281 Epoch ---\n",
      "[Train] loss:0.013548663351684809\n",
      "[Valid] loss:0.0065292129293084145\n",
      "--- 282 Epoch ---\n",
      "[Train] loss:0.0128168067894876\n",
      "[Valid] loss:0.005451532080769539\n",
      "--- 283 Epoch ---\n",
      "[Train] loss:0.01577736483886838\n",
      "[Valid] loss:0.006773275323212147\n",
      "--- 284 Epoch ---\n",
      "[Train] loss:0.01965641789138317\n",
      "[Valid] loss:0.008103354834020138\n",
      "--- 285 Epoch ---\n",
      "[Train] loss:0.017604253720492125\n",
      "[Valid] loss:0.007857258431613445\n",
      "--- 286 Epoch ---\n",
      "[Train] loss:0.015073759015649557\n",
      "[Valid] loss:0.00620528357103467\n",
      "--- 287 Epoch ---\n",
      "[Train] loss:0.013394583947956562\n",
      "[Valid] loss:0.0065428041853010654\n",
      "--- 288 Epoch ---\n",
      "[Train] loss:0.022976303938776255\n",
      "[Valid] loss:0.007280939724296331\n",
      "--- 289 Epoch ---\n",
      "[Train] loss:0.015783661976456642\n",
      "[Valid] loss:0.0067809452302753925\n",
      "--- 290 Epoch ---\n",
      "[Train] loss:0.01901801023632288\n",
      "[Valid] loss:0.005335295107215643\n",
      "--- 291 Epoch ---\n",
      "[Train] loss:0.013997967354953289\n",
      "[Valid] loss:0.005795002914965153\n",
      "--- 292 Epoch ---\n",
      "[Train] loss:0.013142249314114451\n",
      "[Valid] loss:0.006146557629108429\n",
      "--- 293 Epoch ---\n",
      "[Train] loss:0.012432355899363756\n",
      "[Valid] loss:0.006661959458142519\n",
      "--- 294 Epoch ---\n",
      "[Train] loss:0.017440680880099535\n",
      "[Valid] loss:0.008733757771551609\n",
      "--- 295 Epoch ---\n",
      "[Train] loss:0.01568383490666747\n",
      "[Valid] loss:0.006422949954867363\n",
      "--- 296 Epoch ---\n",
      "[Train] loss:0.01633846713230014\n",
      "[Valid] loss:0.0055919368751347065\n",
      "--- 297 Epoch ---\n",
      "[Train] loss:0.009952858090400696\n",
      "[Valid] loss:0.004436860326677561\n",
      "--- 298 Epoch ---\n",
      "[Train] loss:0.015279860235750675\n",
      "[Valid] loss:0.0052678873762488365\n",
      "--- 299 Epoch ---\n",
      "[Train] loss:0.013662413693964481\n",
      "[Valid] loss:0.005235296208411455\n",
      "--- 300 Epoch ---\n",
      "[Train] loss:0.01584176393225789\n",
      "[Valid] loss:0.004496053792536259\n",
      "--- 301 Epoch ---\n",
      "[Train] loss:0.013495358638465405\n",
      "[Valid] loss:0.004762567114084959\n",
      "--- 302 Epoch ---\n",
      "[Train] loss:0.02277697715908289\n",
      "[Valid] loss:0.006568531971424818\n",
      "--- 303 Epoch ---\n",
      "[Train] loss:0.012582621071487665\n",
      "[Valid] loss:0.004422082100063562\n",
      "--- 304 Epoch ---\n",
      "[Train] loss:0.013389624655246735\n",
      "[Valid] loss:0.006368832662701607\n",
      "--- 305 Epoch ---\n",
      "[Train] loss:0.014786478597670794\n",
      "[Valid] loss:0.005218460690230131\n",
      "--- 306 Epoch ---\n",
      "[Train] loss:0.01333888666704297\n",
      "[Valid] loss:0.006381879094988108\n",
      "--- 307 Epoch ---\n",
      "[Train] loss:0.013932360336184502\n",
      "[Valid] loss:0.009758512489497662\n",
      "--- 308 Epoch ---\n",
      "[Train] loss:0.01727411150932312\n",
      "[Valid] loss:0.0063413409516215324\n",
      "--- 309 Epoch ---\n",
      "[Train] loss:0.015695948619395494\n",
      "[Valid] loss:0.005528599955141544\n",
      "--- 310 Epoch ---\n",
      "[Train] loss:0.020364865195006132\n",
      "[Valid] loss:0.005369882099330425\n",
      "--- 311 Epoch ---\n",
      "[Train] loss:0.011417357251048088\n",
      "[Valid] loss:0.007593715097755194\n",
      "--- 312 Epoch ---\n",
      "[Train] loss:0.02126741176471114\n",
      "[Valid] loss:0.006854750216007233\n",
      "--- 313 Epoch ---\n",
      "[Train] loss:0.024111179634928703\n",
      "[Valid] loss:0.005240681581199169\n",
      "--- 314 Epoch ---\n",
      "[Train] loss:0.01587818656116724\n",
      "[Valid] loss:0.005032429471611977\n",
      "--- 315 Epoch ---\n",
      "[Train] loss:0.014693410135805607\n",
      "[Valid] loss:0.0060761491768062115\n",
      "--- 316 Epoch ---\n",
      "[Train] loss:0.019345799926668406\n",
      "[Valid] loss:0.006477666087448597\n",
      "--- 317 Epoch ---\n",
      "[Train] loss:0.01628286112099886\n",
      "[Valid] loss:0.006475731730461121\n",
      "--- 318 Epoch ---\n",
      "[Train] loss:0.011549893766641617\n",
      "[Valid] loss:0.007107975892722607\n",
      "--- 319 Epoch ---\n",
      "[Train] loss:0.01720917411148548\n",
      "[Valid] loss:0.00664929486811161\n",
      "--- 320 Epoch ---\n",
      "[Train] loss:0.00937160337343812\n",
      "[Valid] loss:0.005329928360879421\n",
      "--- 321 Epoch ---\n",
      "[Train] loss:0.014251224230974913\n",
      "[Valid] loss:0.007213668432086706\n",
      "--- 322 Epoch ---\n",
      "[Train] loss:0.0145051428116858\n",
      "[Valid] loss:0.00707595469430089\n",
      "--- 323 Epoch ---\n",
      "[Train] loss:0.010504763573408127\n",
      "[Valid] loss:0.005381477996706963\n",
      "--- 324 Epoch ---\n",
      "[Train] loss:0.015770673053339124\n",
      "[Valid] loss:0.007127752527594566\n",
      "--- 325 Epoch ---\n",
      "[Train] loss:0.012895885854959488\n",
      "[Valid] loss:0.004994173068553209\n",
      "--- 326 Epoch ---\n",
      "[Train] loss:0.014918203931301832\n",
      "[Valid] loss:0.005593465641140938\n",
      "--- 327 Epoch ---\n",
      "[Train] loss:0.017347260378301144\n",
      "[Valid] loss:0.006718936376273632\n",
      "--- 328 Epoch ---\n",
      "[Train] loss:0.013630217872560024\n",
      "[Valid] loss:0.005836174823343754\n",
      "--- 329 Epoch ---\n",
      "[Train] loss:0.01013329066336155\n",
      "[Valid] loss:0.004966577515006065\n",
      "--- 330 Epoch ---\n",
      "[Train] loss:0.018931532744318247\n",
      "[Valid] loss:0.005146258510649204\n",
      "--- 331 Epoch ---\n",
      "[Train] loss:0.012707202229648829\n",
      "[Valid] loss:0.003444540547206998\n",
      "--- 332 Epoch ---\n",
      "[Train] loss:0.011101849842816591\n",
      "[Valid] loss:0.003927032928913832\n",
      "--- 333 Epoch ---\n",
      "[Train] loss:0.015619241632521152\n",
      "[Valid] loss:0.0034331767819821835\n",
      "--- 334 Epoch ---\n",
      "[Train] loss:0.020456241443753242\n",
      "[Valid] loss:0.005045103840529919\n",
      "--- 335 Epoch ---\n",
      "[Train] loss:0.0110598208848387\n",
      "[Valid] loss:0.006467687897384167\n",
      "--- 336 Epoch ---\n",
      "[Train] loss:0.014124147593975067\n",
      "[Valid] loss:0.00761199789121747\n",
      "--- 337 Epoch ---\n",
      "[Train] loss:0.01844879938289523\n",
      "[Valid] loss:0.004745188169181347\n",
      "--- 338 Epoch ---\n",
      "[Train] loss:0.02095678774639964\n",
      "[Valid] loss:0.005076669622212648\n",
      "--- 339 Epoch ---\n",
      "[Train] loss:0.012750156689435244\n",
      "[Valid] loss:0.004308750852942467\n",
      "--- 340 Epoch ---\n",
      "[Train] loss:0.01139824092388153\n",
      "[Valid] loss:0.005365237593650818\n",
      "--- 341 Epoch ---\n",
      "[Train] loss:0.026286681182682514\n",
      "[Valid] loss:0.00563109340146184\n",
      "--- 342 Epoch ---\n",
      "[Train] loss:0.011289418209344149\n",
      "[Valid] loss:0.005715140141546726\n",
      "--- 343 Epoch ---\n",
      "[Train] loss:0.011200719978660345\n",
      "[Valid] loss:0.006327176000922918\n",
      "--- 344 Epoch ---\n",
      "[Train] loss:0.03337185177952051\n",
      "[Valid] loss:0.004130066838115454\n",
      "--- 345 Epoch ---\n",
      "[Train] loss:0.008950869552791119\n",
      "[Valid] loss:0.0051138452254235744\n",
      "--- 346 Epoch ---\n",
      "[Train] loss:0.009072778280824423\n",
      "[Valid] loss:0.006729963235557079\n",
      "--- 347 Epoch ---\n",
      "[Train] loss:0.015100679360330105\n",
      "[Valid] loss:0.00539943715557456\n",
      "--- 348 Epoch ---\n",
      "[Train] loss:0.011295374017208815\n",
      "[Valid] loss:0.005678401794284582\n",
      "--- 349 Epoch ---\n",
      "[Train] loss:0.011250845156610012\n",
      "[Valid] loss:0.0062689632177352905\n",
      "--- 350 Epoch ---\n",
      "[Train] loss:0.03345216391608119\n",
      "[Valid] loss:0.004572474397718906\n",
      "--- 351 Epoch ---\n",
      "[Train] loss:0.014754252973943949\n",
      "[Valid] loss:0.008004074916243553\n",
      "--- 352 Epoch ---\n",
      "[Train] loss:0.013296041637659073\n",
      "[Valid] loss:0.00651697488501668\n",
      "--- 353 Epoch ---\n",
      "[Train] loss:0.014035806525498629\n",
      "[Valid] loss:0.007786961272358894\n",
      "--- 354 Epoch ---\n",
      "[Train] loss:0.015529963187873363\n",
      "[Valid] loss:0.007997716777026653\n",
      "--- 355 Epoch ---\n",
      "[Train] loss:0.013723802752792835\n",
      "[Valid] loss:0.007117318920791149\n",
      "--- 356 Epoch ---\n",
      "[Train] loss:0.01871829805895686\n",
      "[Valid] loss:0.0062294029630720615\n",
      "--- 357 Epoch ---\n",
      "[Train] loss:0.015702576376497746\n",
      "[Valid] loss:0.0085155563428998\n",
      "--- 358 Epoch ---\n",
      "[Train] loss:0.01057202136144042\n",
      "[Valid] loss:0.0052373274229466915\n",
      "--- 359 Epoch ---\n",
      "[Train] loss:0.016847448190674186\n",
      "[Valid] loss:0.0066087692975997925\n",
      "--- 360 Epoch ---\n",
      "[Train] loss:0.007795808836817741\n",
      "[Valid] loss:0.005291799549013376\n",
      "--- 361 Epoch ---\n",
      "[Train] loss:0.013383121695369482\n",
      "[Valid] loss:0.005813478957861662\n",
      "--- 362 Epoch ---\n",
      "[Train] loss:0.01827789144590497\n",
      "[Valid] loss:0.005699127446860075\n",
      "--- 363 Epoch ---\n",
      "[Train] loss:0.012195028131827712\n",
      "[Valid] loss:0.005584079306572676\n",
      "--- 364 Epoch ---\n",
      "[Train] loss:0.012413856573402882\n",
      "[Valid] loss:0.007557823788374662\n",
      "--- 365 Epoch ---\n",
      "[Train] loss:0.014413695549592376\n",
      "[Valid] loss:0.004882581532001495\n",
      "--- 366 Epoch ---\n",
      "[Train] loss:0.008967786561697721\n",
      "[Valid] loss:0.004821151029318571\n",
      "--- 367 Epoch ---\n",
      "[Train] loss:0.012198588345199823\n",
      "[Valid] loss:0.0048902141861617565\n",
      "--- 368 Epoch ---\n",
      "[Train] loss:0.00987533899024129\n",
      "[Valid] loss:0.007163532543927431\n",
      "--- 369 Epoch ---\n",
      "[Train] loss:0.02288846205919981\n",
      "[Valid] loss:0.0052956100553274155\n",
      "--- 370 Epoch ---\n",
      "[Train] loss:0.011162810493260622\n",
      "[Valid] loss:0.004420054145157337\n",
      "--- 371 Epoch ---\n",
      "[Train] loss:0.009596476331353188\n",
      "[Valid] loss:0.003791465424001217\n",
      "--- 372 Epoch ---\n",
      "[Train] loss:0.011635920498520136\n",
      "[Valid] loss:0.00328876287676394\n",
      "--- 373 Epoch ---\n",
      "[Train] loss:0.010940576903522015\n",
      "[Valid] loss:0.004117915406823158\n",
      "--- 374 Epoch ---\n",
      "[Train] loss:0.013351257890462875\n",
      "[Valid] loss:0.004486049059778452\n",
      "--- 375 Epoch ---\n",
      "[Train] loss:0.017969395965337753\n",
      "[Valid] loss:0.003782808082178235\n",
      "--- 376 Epoch ---\n",
      "[Train] loss:0.011666545644402504\n",
      "[Valid] loss:0.00563083728775382\n",
      "--- 377 Epoch ---\n",
      "[Train] loss:0.01848137378692627\n",
      "[Valid] loss:0.004505953285843134\n",
      "--- 378 Epoch ---\n",
      "[Train] loss:0.01803590590134263\n",
      "[Valid] loss:0.006121544633060694\n",
      "--- 379 Epoch ---\n",
      "[Train] loss:0.01130707305856049\n",
      "[Valid] loss:0.004153931513428688\n",
      "--- 380 Epoch ---\n",
      "[Train] loss:0.013121308293193579\n",
      "[Valid] loss:0.0037859829608350992\n",
      "--- 381 Epoch ---\n",
      "[Train] loss:0.0129511090926826\n",
      "[Valid] loss:0.0035227967891842127\n",
      "--- 382 Epoch ---\n",
      "[Train] loss:0.010459433775395155\n",
      "[Valid] loss:0.005982044618576765\n",
      "--- 383 Epoch ---\n",
      "[Train] loss:0.010830868501216173\n",
      "[Valid] loss:0.0034674869384616613\n",
      "--- 384 Epoch ---\n",
      "[Train] loss:0.010175877250730991\n",
      "[Valid] loss:0.005542305298149586\n",
      "--- 385 Epoch ---\n",
      "[Train] loss:0.012033041100949049\n",
      "[Valid] loss:0.004932201001793146\n",
      "--- 386 Epoch ---\n",
      "[Train] loss:0.01480843685567379\n",
      "[Valid] loss:0.005679474212229252\n",
      "--- 387 Epoch ---\n",
      "[Train] loss:0.022829746827483177\n",
      "[Valid] loss:0.004575804341584444\n",
      "--- 388 Epoch ---\n",
      "[Train] loss:0.024785908870398998\n",
      "[Valid] loss:0.005455454811453819\n",
      "--- 389 Epoch ---\n",
      "[Train] loss:0.009898233227431774\n",
      "[Valid] loss:0.004841373302042484\n",
      "--- 390 Epoch ---\n",
      "[Train] loss:0.012971979565918446\n",
      "[Valid] loss:0.005388654302805662\n",
      "--- 391 Epoch ---\n",
      "[Train] loss:0.01295111607760191\n",
      "[Valid] loss:0.005168155767023563\n",
      "--- 392 Epoch ---\n",
      "[Train] loss:0.015237652696669102\n",
      "[Valid] loss:0.005483439192175865\n",
      "--- 393 Epoch ---\n",
      "[Train] loss:0.00933968834578991\n",
      "[Valid] loss:0.005190176423639059\n",
      "--- 394 Epoch ---\n",
      "[Train] loss:0.011503380723297596\n",
      "[Valid] loss:0.007298070006072521\n",
      "--- 395 Epoch ---\n",
      "[Train] loss:0.010769713204354048\n",
      "[Valid] loss:0.0025991310831159353\n",
      "--- 396 Epoch ---\n",
      "[Train] loss:0.008735343581065536\n",
      "[Valid] loss:0.0031410420779138803\n",
      "--- 397 Epoch ---\n",
      "[Train] loss:0.014163637533783913\n",
      "[Valid] loss:0.003779016202315688\n",
      "--- 398 Epoch ---\n",
      "[Train] loss:0.02051993552595377\n",
      "[Valid] loss:0.003970897290855646\n",
      "--- 399 Epoch ---\n",
      "[Train] loss:0.014497759751975536\n",
      "[Valid] loss:0.007985061034560204\n",
      "--- 400 Epoch ---\n",
      "[Train] loss:0.012006300035864115\n",
      "[Valid] loss:0.0036552429664880037\n",
      "--- 401 Epoch ---\n",
      "[Train] loss:0.015427174977958202\n",
      "[Valid] loss:0.005706844385713339\n",
      "--- 402 Epoch ---\n",
      "[Train] loss:0.01177797932177782\n",
      "[Valid] loss:0.005207163281738758\n",
      "--- 403 Epoch ---\n",
      "[Train] loss:0.010787648614495993\n",
      "[Valid] loss:0.008231526240706444\n",
      "--- 404 Epoch ---\n",
      "[Train] loss:0.011120886309072375\n",
      "[Valid] loss:0.006462145131081343\n",
      "--- 405 Epoch ---\n",
      "[Train] loss:0.010090835858136415\n",
      "[Valid] loss:0.0038464481476694345\n",
      "--- 406 Epoch ---\n",
      "[Train] loss:0.01683110697194934\n",
      "[Valid] loss:0.0033348826691508293\n",
      "--- 407 Epoch ---\n",
      "[Train] loss:0.01787168812006712\n",
      "[Valid] loss:0.0035411675926297903\n",
      "--- 408 Epoch ---\n",
      "[Train] loss:0.0161779522895813\n",
      "[Valid] loss:0.00802348181605339\n",
      "--- 409 Epoch ---\n",
      "[Train] loss:0.01845851307734847\n",
      "[Valid] loss:0.0049424003809690475\n",
      "--- 410 Epoch ---\n",
      "[Train] loss:0.01723109418526292\n",
      "[Valid] loss:0.003962812013924122\n",
      "--- 411 Epoch ---\n",
      "[Train] loss:0.020681691356003284\n",
      "[Valid] loss:0.003892716718837619\n",
      "--- 412 Epoch ---\n",
      "[Train] loss:0.02074487693607807\n",
      "[Valid] loss:0.005261579062789679\n",
      "--- 413 Epoch ---\n",
      "[Train] loss:0.010530389379709959\n",
      "[Valid] loss:0.005352092906832695\n",
      "--- 414 Epoch ---\n",
      "[Train] loss:0.010081426240503788\n",
      "[Valid] loss:0.006538643501698971\n",
      "--- 415 Epoch ---\n",
      "[Train] loss:0.008815733715891838\n",
      "[Valid] loss:0.007502010557800531\n",
      "--- 416 Epoch ---\n",
      "[Train] loss:0.009137703804299235\n",
      "[Valid] loss:0.004834611900150776\n",
      "--- 417 Epoch ---\n",
      "[Train] loss:0.008937276201322675\n",
      "[Valid] loss:0.004239697940647602\n",
      "--- 418 Epoch ---\n",
      "[Train] loss:0.009960223454982042\n",
      "[Valid] loss:0.004565191455185413\n",
      "--- 419 Epoch ---\n",
      "[Train] loss:0.011622346937656403\n",
      "[Valid] loss:0.004359113983809948\n",
      "--- 420 Epoch ---\n",
      "[Train] loss:0.012981142615899444\n",
      "[Valid] loss:0.006867264863103628\n",
      "--- 421 Epoch ---\n",
      "[Train] loss:0.010075191967189312\n",
      "[Valid] loss:0.007334493566304445\n",
      "--- 422 Epoch ---\n",
      "[Train] loss:0.010647325310856104\n",
      "[Valid] loss:0.0061012133955955505\n",
      "--- 423 Epoch ---\n",
      "[Train] loss:0.011463957373052835\n",
      "[Valid] loss:0.0037364615127444267\n",
      "--- 424 Epoch ---\n",
      "[Train] loss:0.010050474433228374\n",
      "[Valid] loss:0.0037878011353313923\n",
      "--- 425 Epoch ---\n",
      "[Train] loss:0.00817119562998414\n",
      "[Valid] loss:0.0057203578762710094\n",
      "--- 426 Epoch ---\n",
      "[Train] loss:0.010668633971363306\n",
      "[Valid] loss:0.0038221450522542\n",
      "--- 427 Epoch ---\n",
      "[Train] loss:0.014027072116732597\n",
      "[Valid] loss:0.0033506618347018957\n",
      "--- 428 Epoch ---\n",
      "[Train] loss:0.013070040382444859\n",
      "[Valid] loss:0.002905589295551181\n",
      "--- 429 Epoch ---\n",
      "[Train] loss:0.008922982029616833\n",
      "[Valid] loss:0.007597662974148989\n",
      "--- 430 Epoch ---\n",
      "[Train] loss:0.014579401351511478\n",
      "[Valid] loss:0.002961855847388506\n",
      "--- 431 Epoch ---\n",
      "[Train] loss:0.012197932694107294\n",
      "[Valid] loss:0.003199153346940875\n",
      "--- 432 Epoch ---\n",
      "[Train] loss:0.015340008772909641\n",
      "[Valid] loss:0.0028804237954318523\n",
      "--- 433 Epoch ---\n",
      "[Train] loss:0.0070238616317510605\n",
      "[Valid] loss:0.003977926913648844\n",
      "--- 434 Epoch ---\n",
      "[Train] loss:0.01344598038122058\n",
      "[Valid] loss:0.004145401995629072\n",
      "--- 435 Epoch ---\n",
      "[Train] loss:0.01479333359748125\n",
      "[Valid] loss:0.005491076037287712\n",
      "--- 436 Epoch ---\n",
      "[Train] loss:0.012911983765661716\n",
      "[Valid] loss:0.004200729541480541\n",
      "--- 437 Epoch ---\n",
      "[Train] loss:0.011254832148551941\n",
      "[Valid] loss:0.004035781603306532\n",
      "--- 438 Epoch ---\n",
      "[Train] loss:0.011592732276767492\n",
      "[Valid] loss:0.00399001082405448\n",
      "--- 439 Epoch ---\n",
      "[Train] loss:0.013723017647862434\n",
      "[Valid] loss:0.003646425437182188\n",
      "--- 440 Epoch ---\n",
      "[Train] loss:0.018306049052625895\n",
      "[Valid] loss:0.004402515012770891\n",
      "--- 441 Epoch ---\n",
      "[Train] loss:0.01234341785311699\n",
      "[Valid] loss:0.003950885031372309\n",
      "--- 442 Epoch ---\n",
      "[Train] loss:0.009836922865360975\n",
      "[Valid] loss:0.003096225904300809\n",
      "--- 443 Epoch ---\n",
      "[Train] loss:0.011698869988322258\n",
      "[Valid] loss:0.0037637725472450256\n",
      "--- 444 Epoch ---\n",
      "[Train] loss:0.012334158178418875\n",
      "[Valid] loss:0.003772416850551963\n",
      "--- 445 Epoch ---\n",
      "[Train] loss:0.011139859445393085\n",
      "[Valid] loss:0.003404631745070219\n",
      "--- 446 Epoch ---\n",
      "[Train] loss:0.014724824577569962\n",
      "[Valid] loss:0.003649289021268487\n",
      "--- 447 Epoch ---\n",
      "[Train] loss:0.013935090973973274\n",
      "[Valid] loss:0.004503076430410147\n",
      "--- 448 Epoch ---\n",
      "[Train] loss:0.013600326143205166\n",
      "[Valid] loss:0.0023793508298695087\n",
      "--- 449 Epoch ---\n",
      "[Train] loss:0.009828795911744237\n",
      "[Valid] loss:0.005151727702468634\n",
      "--- 450 Epoch ---\n",
      "[Train] loss:0.009155063889920712\n",
      "[Valid] loss:0.004961975384503603\n",
      "--- 451 Epoch ---\n",
      "[Train] loss:0.011448586825281382\n",
      "[Valid] loss:0.0055745067074894905\n",
      "--- 452 Epoch ---\n",
      "[Train] loss:0.011942386627197266\n",
      "[Valid] loss:0.004144989885389805\n",
      "--- 453 Epoch ---\n",
      "[Train] loss:0.006117181153967977\n",
      "[Valid] loss:0.004025032743811607\n",
      "--- 454 Epoch ---\n",
      "[Train] loss:0.017140410840511322\n",
      "[Valid] loss:0.00439710495993495\n",
      "--- 455 Epoch ---\n",
      "[Train] loss:0.013596284203231335\n",
      "[Valid] loss:0.003639464732259512\n",
      "--- 456 Epoch ---\n",
      "[Train] loss:0.007837532320991158\n",
      "[Valid] loss:0.0037192548625171185\n",
      "--- 457 Epoch ---\n",
      "[Train] loss:0.012269412633031607\n",
      "[Valid] loss:0.0033507931511849165\n",
      "--- 458 Epoch ---\n",
      "[Train] loss:0.012635651975870132\n",
      "[Valid] loss:0.004762740805745125\n",
      "--- 459 Epoch ---\n",
      "[Train] loss:0.007732900092378259\n",
      "[Valid] loss:0.004229196347296238\n",
      "--- 460 Epoch ---\n",
      "[Train] loss:0.009610852226614952\n",
      "[Valid] loss:0.003558761440217495\n",
      "--- 461 Epoch ---\n",
      "[Train] loss:0.010839864145964384\n",
      "[Valid] loss:0.004620034713298082\n",
      "--- 462 Epoch ---\n",
      "[Train] loss:0.007452576421201229\n",
      "[Valid] loss:0.005840369034558535\n",
      "--- 463 Epoch ---\n",
      "[Train] loss:0.009591469774022698\n",
      "[Valid] loss:0.003134338650852442\n",
      "--- 464 Epoch ---\n",
      "[Train] loss:0.01409633457660675\n",
      "[Valid] loss:0.0029859363567084074\n",
      "--- 465 Epoch ---\n",
      "[Train] loss:0.012383014429360628\n",
      "[Valid] loss:0.003683642949908972\n",
      "--- 466 Epoch ---\n",
      "[Train] loss:0.01450948091223836\n",
      "[Valid] loss:0.003332781605422497\n",
      "--- 467 Epoch ---\n",
      "[Train] loss:0.008379550650715828\n",
      "[Valid] loss:0.004188337828963995\n",
      "--- 468 Epoch ---\n",
      "[Train] loss:0.01117123500443995\n",
      "[Valid] loss:0.0031838829163461924\n",
      "--- 469 Epoch ---\n",
      "[Train] loss:0.008044628892093897\n",
      "[Valid] loss:0.003149089403450489\n",
      "--- 470 Epoch ---\n",
      "[Train] loss:0.01346657844260335\n",
      "[Valid] loss:0.004426327534019947\n",
      "--- 471 Epoch ---\n",
      "[Train] loss:0.00993486330844462\n",
      "[Valid] loss:0.0041103670373559\n",
      "--- 472 Epoch ---\n",
      "[Train] loss:0.00813829549588263\n",
      "[Valid] loss:0.0040833791717886925\n",
      "--- 473 Epoch ---\n",
      "[Train] loss:0.008902138099074364\n",
      "[Valid] loss:0.006449450273066759\n",
      "--- 474 Epoch ---\n",
      "[Train] loss:0.014498624950647354\n",
      "[Valid] loss:0.004815102554857731\n",
      "--- 475 Epoch ---\n",
      "[Train] loss:0.01042611664161086\n",
      "[Valid] loss:0.005558749660849571\n",
      "--- 476 Epoch ---\n",
      "[Train] loss:0.00898260623216629\n",
      "[Valid] loss:0.006548220757395029\n",
      "--- 477 Epoch ---\n",
      "[Train] loss:0.012808633502572775\n",
      "[Valid] loss:0.005033328663557768\n",
      "--- 478 Epoch ---\n",
      "[Train] loss:0.013147178571671247\n",
      "[Valid] loss:0.003059112001210451\n",
      "--- 479 Epoch ---\n",
      "[Train] loss:0.010323301889002323\n",
      "[Valid] loss:0.0023733500856906176\n",
      "--- 480 Epoch ---\n",
      "[Train] loss:0.009371139109134674\n",
      "[Valid] loss:0.004029572010040283\n",
      "--- 481 Epoch ---\n",
      "[Train] loss:0.013454335276037455\n",
      "[Valid] loss:0.00407283054664731\n",
      "--- 482 Epoch ---\n",
      "[Train] loss:0.022596866823732853\n",
      "[Valid] loss:0.004882258828729391\n",
      "--- 483 Epoch ---\n",
      "[Train] loss:0.009611814748495817\n",
      "[Valid] loss:0.003909860737621784\n",
      "--- 484 Epoch ---\n",
      "[Train] loss:0.009940850548446178\n",
      "[Valid] loss:0.004516084212809801\n",
      "--- 485 Epoch ---\n",
      "[Train] loss:0.0072331782430410385\n",
      "[Valid] loss:0.00501313665881753\n",
      "--- 486 Epoch ---\n",
      "[Train] loss:0.015359519049525261\n",
      "[Valid] loss:0.0036950509529560804\n",
      "--- 487 Epoch ---\n",
      "[Train] loss:0.008494915906339884\n",
      "[Valid] loss:0.004243865143507719\n",
      "--- 488 Epoch ---\n",
      "[Train] loss:0.011059038108214736\n",
      "[Valid] loss:0.003816691692918539\n",
      "--- 489 Epoch ---\n",
      "[Train] loss:0.01625619549304247\n",
      "[Valid] loss:0.0026445884723216295\n",
      "--- 490 Epoch ---\n",
      "[Train] loss:0.00702802580781281\n",
      "[Valid] loss:0.0040725478902459145\n",
      "--- 491 Epoch ---\n",
      "[Train] loss:0.014865847770124674\n",
      "[Valid] loss:0.0029882637318223715\n",
      "--- 492 Epoch ---\n",
      "[Train] loss:0.014710438437759876\n",
      "[Valid] loss:0.0038054550532251596\n",
      "--- 493 Epoch ---\n",
      "[Train] loss:0.012302326038479805\n",
      "[Valid] loss:0.0039443401619791985\n",
      "--- 494 Epoch ---\n",
      "[Train] loss:0.008237323025241494\n",
      "[Valid] loss:0.004342508036643267\n",
      "--- 495 Epoch ---\n",
      "[Train] loss:0.007546629756689072\n",
      "[Valid] loss:0.005030496045947075\n",
      "--- 496 Epoch ---\n",
      "[Train] loss:0.010086188558489084\n",
      "[Valid] loss:0.006222629453986883\n",
      "--- 497 Epoch ---\n",
      "[Train] loss:0.017330489587038755\n",
      "[Valid] loss:0.004262207075953484\n",
      "--- 498 Epoch ---\n",
      "[Train] loss:0.00862607080489397\n",
      "[Valid] loss:0.004715211223810911\n",
      "--- 499 Epoch ---\n",
      "[Train] loss:0.010683040600270033\n",
      "[Valid] loss:0.003920025657862425\n",
      "--- 500 Epoch ---\n",
      "[Train] loss:0.009978306945413351\n",
      "[Valid] loss:0.003581446595489979\n",
      "--- finish ---\n",
      "The best epoch of valid loss : Epoch:{} 479\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    print('--- {} Epoch ---'.format(epoch+1))\n",
    "    train_valid('train',net,train_loader,loss_function,optim,train_history)\n",
    "    train_valid('valid',net,valid_loader,loss_function,optim,valid_history)\n",
    "    \n",
    "    if min(valid_history['loss']) == valid_history['loss'][-1]:\n",
    "        torch.save(net.state_dict(), './outputs/'+'best_model.pth')\n",
    "\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        plot_graph(train_history['loss'], valid_history['loss'])\n",
    "\n",
    "print('--- finish ---')\n",
    "epoch = valid_history['loss'].index(min(valid_history['loss']))+1\n",
    "print('The best epoch of valid loss : Epoch:{}', epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
